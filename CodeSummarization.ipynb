{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-Gj0kIyqjkx"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline, RobertaTokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from math import sqrt\n",
    "from google.colab import files\n",
    "import shutil\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "4d3bca6d8879407387ba4976bd2cd12e",
      "5d3b66ed2b384737a29be6243e995f34"
     ]
    },
    "id": "XR_jzOWTmFml",
    "outputId": "d2439eca-7110-4f5a-e844-9338ec88c56f"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cX_WQNr2v8fg"
   },
   "source": [
    "# **DF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "B8bAY4ryyCU5",
    "outputId": "2c3e541e-a3d7-4a96-b092-35d5b56f973e"
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"java_test_code_and_docs.csv\", header=None)\n",
    "test_df.columns = [\"Code\",\"Summary\"]\n",
    "test_df=test_df[1:]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qW9SJw32PF4R"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"Java_train_data.csv\", header=None)\n",
    "train_df.columns = [\"Code\",\"Summary\"]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1yjxCXzv3B2"
   },
   "source": [
    "# **Pre Processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAllsIRrv3Ji"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_good_summary_text(summary):\n",
    "    # Convert to string (in case of None or non-string input)\n",
    "    if \"@\" in summary:\n",
    "      return False\n",
    "    if \"<\" in summary:\n",
    "      return False\n",
    "    if len(summary.split())<15:\n",
    "      return False\n",
    "\n",
    "    # If it passes all filters, return True\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQRY7xoVwDoS"
   },
   "outputs": [],
   "source": [
    "train_df[\"check\"] = train_df[\"Summary\"].apply(lambda x: is_good_summary_text(x))\n",
    "filtered_train = train_df[train_df[\"check\"] == True]\n",
    "filtered_train=filtered_train[320:480]\n",
    "filtered_train.drop(columns=[\"check\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6Q8_qirwFV-",
    "outputId": "3567369a-5801-4130-b084-37d34442d795"
   },
   "outputs": [],
   "source": [
    "test_df[\"check\"] = test_df[\"Summary\"].apply(lambda x: is_good_summary_text(x))\n",
    "test_df = test_df[test_df[\"check\"] == True]\n",
    "test_df.drop(columns=[\"check\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "d64fTGQR39oO",
    "outputId": "b1ce02ee-f996-4d23-db5a-2253277c8dc3"
   },
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mago2Gv3PBIl"
   },
   "source": [
    "# **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f4rWOcelPGAK"
   },
   "outputs": [],
   "source": [
    "# Initialize the tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"java_db_320\")\n",
    "\n",
    "# Convert your DataFrame to a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(filtered_train)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    codes = [code if code is not None else \"\" for code in examples[\"Code\"]]\n",
    "    summaries = [summ if summ is not None else \"\" for summ in examples[\"Summary\"]]\n",
    "\n",
    "    summarize_prompts = [\n",
    "        f\"\"\"\n",
    "        You are a summarization assistant specialized in analyzing Java code. Your task is to generate a concise and accurate summary of the provided Java code.\n",
    "\n",
    "        Focus on the following:\n",
    "        1. The main purpose of the class and its role in the application.\n",
    "        2. Key behaviors and methods implemented in the class.\n",
    "        3. How the class interacts with other components of the system or game.\n",
    "\n",
    "        Do not:\n",
    "        - Repeat inheritance details unnecessarily.\n",
    "        - Include redundant or inaccurate references.\n",
    "        - Use overly technical jargon; keep the summary accessible.\n",
    "\n",
    "        Here is the Java code:\n",
    "        {code}\n",
    "        \"\"\" for code in codes\n",
    "    ]\n",
    "\n",
    "    input_encodings = tokenizer(\n",
    "        summarize_prompts,\n",
    "        max_length=512,  # Reduced max length for efficiency\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    target_encodings = tokenizer(\n",
    "        summaries,\n",
    "        max_length=128,  # Reduced max length for summaries\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    input_encodings[\"labels\"] = target_encodings[\"input_ids\"]\n",
    "    return input_encodings\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=[\"Code\", \"Summary\"])\n",
    "\n",
    "# Split into train and test sets\n",
    "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "test_dataset = train_test_split[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-O3RfFFPGEa"
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained CodeT5 model\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"java_db_320\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",           # Output directory\n",
    "    evaluation_strategy=\"epoch\",     # Evaluate after each epoch\n",
    "    learning_rate=5e-5,              # Learning rate\n",
    "    per_device_train_batch_size=4,   # Batch size for training\n",
    "    per_device_eval_batch_size=4,    # Batch size for evaluation\n",
    "    num_train_epochs=10,              # Number of epochs\n",
    "    save_strategy=\"epoch\",           # Save model after every epoch\n",
    "    logging_dir=\"./logs\",            # Directory for logs\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    fp16=True,\n",
    "    load_best_model_at_end=True,  # Load best model at the end\n",
    "    metric_for_best_model=\"eval_loss\",  # Use eval_loss to track best model\n",
    "    greater_is_better=False,  # Lower loss is better\n",
    "    seed=42  # For reproducibility                   # Use mixed precision (if supported by GPU)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LdSywiShPGJw"
   },
   "outputs": [],
   "source": [
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nKzRKzKhPgns"
   },
   "outputs": [],
   "source": [
    "# Save the model and tokenizer\n",
    "model.save_pretrained(\"java_db_480\")\n",
    "tokenizer.save_pretrained(\"java_db_480\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-fSCYNfmQAEO"
   },
   "outputs": [],
   "source": [
    "# Zip the directory\n",
    "shutil.make_archive(\"java_db_480\", \"zip\", \"java_db_480\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2VWr3fhQoJ_"
   },
   "source": [
    "# **Trained Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4dwj_9rQoWe"
   },
   "outputs": [],
   "source": [
    "# Initialize the tokenizer and model for Java code summarization\n",
    "tokenizer_java = RobertaTokenizer.from_pretrained(\"java_db_320\")\n",
    "model_java = T5ForConditionalGeneration.from_pretrained(\"java_db_320\")\n",
    "\n",
    "def summarize_t5_java(code):\n",
    "    # Generate the summarization prompt with improved instructions\n",
    "    summarize_prompt = \"\"\"\n",
    "    You are a summarization assistant specialized in analyzing Java code. Your task is to generate a concise and accurate summary of the provided Java code.\n",
    "\n",
    "    Focus on the following:\n",
    "    1. The main purpose of the class and its role in the application.\n",
    "    2. Key behaviors and methods implemented in the class.\n",
    "    3. How the class interacts with other components of the system or game.\n",
    "\n",
    "    Do not:\n",
    "    - Repeat inheritance details unnecessarily.\n",
    "    - Include redundant or inaccurate references.\n",
    "    - Use overly technical jargon; keep the summary accessible.\n",
    "\n",
    "    Here is the Java code:\n",
    "    \"\"\" + code\n",
    "\n",
    "    input_ids = tokenizer_java.encode(summarize_prompt, return_tensors=\"pt\", truncation=True)\n",
    "\n",
    "    # Generate the summary directly with improved sampling parameters\n",
    "    summary_ids = model_java.generate(\n",
    "        input_ids,\n",
    "        min_length=50,       # Ensures a meaningful minimum content length\n",
    "        max_length=1024,     # High value to allow long summaries if needed\n",
    "        num_beams=5,         # Improves summarization quality\n",
    "        length_penalty=1.5,  # Balances length and conciseness\n",
    "        temperature=1.0,     # Neutral randomness\n",
    "        top_p=0.9,           # Diverse but controlled output\n",
    "        repetition_penalty=1.2, # Reduces repetitive phrases\n",
    "        early_stopping=True  # Stops once the model determines the end of content\n",
    "    )\n",
    "    summary = tokenizer_java.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Axdhd_dLppxR"
   },
   "source": [
    "# **creating df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VFjFPb_C_5YG"
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"filtered_test_java.csv\")\n",
    "df_test.drop(columns=[\"Summary_t5\"], inplace=True)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nRzNtOdCYyik"
   },
   "source": [
    "# **Cleaning repetitive text in summaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473,
     "referenced_widgets": [
      "3c15a98397774e97bdf8a63cb1f19268",
      "b5da848054a84b0aaaeb2de038798524",
      "d83ddd9fee0a401c9297764a4fe3ca5c",
      "a552d39798064098b03b4be143262eca",
      "774a8ca5a5d44913811f277f82abe93b",
      "97d832bf148142e38512a8826a017132",
      "c2433a0ba7f84c2398cd77d20ccc4965",
      "48e2ac3097194db4864b3800b021d253",
      "ad0e5d95ce2f4735b723060d73e2b593",
      "ae9ab660fabc4ca49d2276889cd546e0",
      "cef569f388c0476abd9ca6abcd4ece3a",
      "942c281e2c4c48dba1622c0dada60683",
      "3a4dcf29852b4af18da853fa5222973d",
      "fe5fb3f022544e69931d9c4b4eb42fbb",
      "ad0fdbe6321a433dbc5672f2ee4fd3fb",
      "e12c1b708ce240bd946b7969796a77fb",
      "0ce3e6d0643043998cbfa923121124a1",
      "4994e3f306c642448edce458ffd2fb85",
      "5dd90387bdaf4d7f9e6c23814bf5c26c",
      "14495db127c54acb9e515005828faaa3",
      "d1a91759ffe74369870515535179de21",
      "bfb88a7933e54371824eca3b4115bb75",
      "0debb7f6e80149ec9eb33b290790b3d1",
      "9ac272e233574922bd8c15577aba8140",
      "a0fc1e22496249ebac19305e60023afb",
      "4ac775d63ef24e3c81f7451b7226d7fa",
      "adfe53afdc874d08998932d24cf03d7d",
      "52d57518c6774318ab098769d8671529",
      "3702a47e27f84d13af048401996756e1",
      "8f58d175b9394b0c86207eda57ef191d",
      "a9da8f6d754444bb8f830529243e5174",
      "b5d03db7c5fd42089c728f0436eabc35",
      "5fe2746d92664be2ae5ec4063674d64e",
      "55323bbdd9d64873942044d663034c87",
      "beadabe89f7d464eb6f3cb16228dcb69",
      "cdc007c1075849be93265f2acfc54721",
      "6f0294bfa4fb4c369f67a42ea7ba3a13",
      "d3c8e80c0d1e4edeabd038b882904315",
      "05150194cb8849a08ed0a4e83cefb34f",
      "cbae04788dac47d4a60cde684ceeb4e9",
      "db86414a16a146d291003c880532715c",
      "0282c1212a064de582de69a83adf87b9",
      "d6441a9e2ead4bdf8524dfee249bba2b",
      "a0b107d4448941e5a1720856572ba493",
      "32b94090e7324a7897de6bc95850c51c",
      "fa7d7cc1130a4951a887bd32f2ba03d8",
      "f91120b8bf03441da904b3eb1647ba60",
      "666757214fe249558cf8dbde99f56bf4",
      "1911fa71f459447fa41ee76580f58184",
      "3dd10a7cc2294d37bd88f8811258258b",
      "301550a53da14ab99c6cc5391508a5d4",
      "082c163c612d4ac5b18f807389cec2ea",
      "564c76201fe44729aa7966bb42adaa7b",
      "4daf58efee414735b5764010b5b585a4",
      "e58cd815d3794bdcaf03edcbba77ab00",
      "3004e95c2ce948c0a6d6553309d22618",
      "6b2675a6a8b94611b99a54964adc6b7e",
      "89c37bedfbc64149bf93b62ffef1e8e8",
      "431186d9721d4f1fb30593b3619a4004",
      "a1c9933358fc4f60afd4e2b755d4e571",
      "cbcc8e36effa412991586956640d18ef",
      "5fbb1e3d0a6341288581626e6cc4385d",
      "604f3c59b5cb4dc8ad2be4a191c5afc2",
      "63d2e4a5e59247309f5cd732f7bd4514",
      "3d15ebea2b8d4e7c9bf27aadd7b35106",
      "8b94e083c62b4cabadc9ae569702b496",
      "ea85266641f34d2d82982e37669b2b88",
      "ee84b7f31ca44ff69201f73e6d3262ec",
      "8dfcdf9abf92474a81285b1da735b1c4",
      "2ab1a3bfb6d3421d9db029b15cb8064b",
      "7705d05061a941dcb21a7d7d4bb44bb5",
      "6c425e73b85c407891bb37213cdd5c85",
      "d4e3bc3f84a24291be5a1ee5788ad949",
      "8b31b128ce6f444fb11de5de5ad8f4bd",
      "054d5955e53e477d9c26cf5e830c61dd",
      "e5146388fbe94177b3c19108855a293d",
      "6c52b3aaf6ca4e14957b6bba887edfb4",
      "600ff4916a584c0eb8eff929c64d61cc",
      "82a51bc280c34ff4a5d412f58911bba6",
      "15c3392529bf4d419521df4cd9f39f47",
      "046d88a8c51441d2aae100c170534907",
      "5eeb071713dc4ec39035d57a9f36af42",
      "428438712cb4443d87d65dba11787abb",
      "942b40d8572c46dea1ae80277b7a911a",
      "77b39e3ce6844cd2b4fe422605eaa06c",
      "8a2ac4d549be4e6982bea69fdc20930d",
      "b2f884959f9f4186a3621cb5cf5ee206",
      "07c7ec8d33a448759b6d29cbcabccb3e",
      "169799947ddb433ea7c218715e3023a2",
      "fd2b43adca2f4ba4b6625179ff0b4f90",
      "4ae7221216a746039c010a00dd833443",
      "a310d4d6c2d24de0b8ddb86cb5b2dcca",
      "f34b4019cd72481ca34cc47d3c76c855",
      "8a22289c5b8b4a91ae2dacf8146bfdf0",
      "deecbbbd48004e1ea6f32fcadb390b4a",
      "9c2e600fb29141878fff355488db17a6",
      "82bba4d0dfc5469393f5d17118394b4a",
      "121883431132471b93ce61097b054aa0",
      "69d48c795648467b99dc06ceb61e01ce",
      "71593a5533e04cc5b93f0700e6e2f8b5",
      "4a0856d0fbed4080953530bb82552dab",
      "4383d7747792478d97d3b2cca7b94998",
      "9f1a5c4e3a8340e3b0ca16d9ebf4bbb3",
      "1efdcaaab4934ca69ab2ca816db2b4ad",
      "72f67593727b4dcfb95a0135835a6150",
      "bdce2c6faf5a4829915ca27723e1b4cf",
      "8c667aebade048299b5a9e2279159831",
      "235556b7051b4ab591775cb79a4bcad6",
      "56c5f9d6d70b47ea9b7d06ba6d61fa44",
      "cb36a57073c44d69b650d7920e777e54",
      "c05191a45a1049e9a069805be3903a96",
      "d4288bb3b51246fba2fb632dd91c481c",
      "306a551a516b4de0960aff74c155cf60",
      "dc63b589c97f4123846b70055c261b13",
      "41a4e95d099e4b4584a7a4353ea6288d",
      "e0b122cd5c8b4e32a727d6553788384f",
      "3c53836c52724bb79120defe48d4d878",
      "1e385f93ed614b6d949925e1cc3d03bc",
      "6fa6e8f6908a4dd3a7440b008f7879ed",
      "4e63a9dec95441b1a6376c660561d36f",
      "720d761dfcbc4edc96b0adbea20c91b3"
     ]
    },
    "id": "C8yPfw-PYyuh",
    "outputId": "53a5c0e2-87c1-4467-9447-5cb8edd7ff92"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# Load SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def remove_semantic_duplicates(text, similarity_threshold=0.8):\n",
    "    # Split the text into sentences using regex to handle various punctuation marks\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
    "\n",
    "    # Encode the complete sentences\n",
    "    embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    # Track unique embeddings\n",
    "    unique_embeddings = []\n",
    "    unique_sentences = []\n",
    "\n",
    "    for i, emb in enumerate(embeddings):\n",
    "        # Check for semantic similarity\n",
    "        if not any(util.cos_sim(emb, unique_emb) > similarity_threshold for unique_emb in unique_embeddings):\n",
    "            unique_embeddings.append(emb)\n",
    "            unique_sentences.append(sentences[i])\n",
    "\n",
    "    # Ensure at least one sentence is always returned\n",
    "    if not unique_sentences:\n",
    "        return sentences[0]\n",
    "\n",
    "    # Return filtered sentences joined with proper punctuation\n",
    "    return ' '.join(unique_sentences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmVU8_tqpvN6"
   },
   "source": [
    "# **summarize code**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jdUElOk45m3e"
   },
   "source": [
    "## **Java Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PfkdsdHs5nKr",
    "outputId": "19375515-f403-48f4-ca99-721c5b288898"
   },
   "outputs": [],
   "source": [
    "\n",
    "test_df=pd.read_csv(\"only_codes.csv\")\n",
    "\n",
    "\n",
    "test_df['Summaries']=test_df[\"func_code_string\"].apply(lambda x: summarize_t5_java(x))\n",
    "test_df['Summaries'] = test_df['Summaries'].apply(lambda x: remove_semantic_duplicates(x))\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cbUtyZ15nTl"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "test_df.to_csv(\"CodeT5_with_summaries.csv\", index=False)\n",
    "files.download(\"CodeT5_with_summaries.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThHU9ysFiJmM"
   },
   "source": [
    "## *overall_semantic_similarity*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgc0e6WLiNpL"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "def calculate_overall_semantic_similarity(reference_texts, generated_texts, model_name='all-MiniLM-L6-v2'):\n",
    "    \"\"\"\n",
    "    Calculate the overall semantic similarity score between two sets of texts.\n",
    "\n",
    "    Args:\n",
    "        reference_texts (list): List of reference texts (gold standard summaries).\n",
    "        generated_texts (list): List of generated texts (model outputs).\n",
    "        model_name (str): Name of the SentenceTransformer model to use (default: 'all-MiniLM-L6-v2').\n",
    "\n",
    "    Returns:\n",
    "        float: Overall semantic similarity score (average of all pairwise scores).\n",
    "    \"\"\"\n",
    "    if not isinstance(reference_texts, list) or not isinstance(generated_texts, list):\n",
    "        raise ValueError(\"Both inputs must be lists of strings.\")\n",
    "\n",
    "    # Load the model\n",
    "    model = SentenceTransformer(model_name)\n",
    "\n",
    "    # Encode the texts\n",
    "    embeddings1 = model.encode(reference_texts, convert_to_tensor=True)\n",
    "    embeddings2 = model.encode(generated_texts, convert_to_tensor=True)\n",
    "\n",
    "    # Compute pairwise semantic similarity\n",
    "    similarities = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "    # Calculate the average similarity score\n",
    "    total_score = similarities.sum().item()\n",
    "    count = similarities.numel()\n",
    "    overall_similarity = round(total_score / count, 4)\n",
    "\n",
    "    return overall_similarity\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371
    },
    "id": "3dWHLPNclRMp",
    "outputId": "2ffa17c9-58a1-4d0f-a80a-3a10641b69a5"
   },
   "outputs": [],
   "source": [
    "filtered_test['Similarity_Score'] = filtered_test.apply(\n",
    "    lambda row: calculate_overall_semantic_similarity(\n",
    "        [row['Summary']],  # Wrapping the single string in a list\n",
    "        [row['Summary_t5']],  # Wrapping the single string in a list\n",
    "        model_name='all-MiniLM-L6-v2'\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cRtUV_uo0tv"
   },
   "outputs": [],
   "source": [
    "filtered_test['Similarity_Score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vAftsyiLQuMy"
   },
   "outputs": [],
   "source": [
    "filtered_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MErzdhhDQGuR"
   },
   "outputs": [],
   "source": [
    "filtered_test = filtered_test.drop(columns=['Summary', 'Similarity_Score'])\n",
    "filtered_test = filtered_test.rename(columns={'Summary_t5': 'Summary'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFn3AY4GQ3_A"
   },
   "outputs": [],
   "source": [
    "filtered_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiEzQ6fn31Cb"
   },
   "outputs": [],
   "source": [
    "filtered_test.to_csv(\"filtered_test_java_500_rows_new_mode.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrNrOM2ug9Gt"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"filtered_test_java_100_rows (1).csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wX6W2vJRiXLB"
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'Summary_t5': 'Summary'})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
